{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def train():\n",
    "    import tensorflow as tf\n",
    "\n",
    "    print(\"TensorFlow version: \", tf.__version__)\n",
    "\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    print(\"Training...\")\n",
    "    model.fit(x_train, y_train, epochs=5, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model on test set\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairing_run():\n",
    "    import uuid\n",
    "    from kubeflow import fairing\n",
    "\n",
    "    CONTAINER_REGISTRY = 'kangwoo'\n",
    "\n",
    "    namespace = 'admin'\n",
    "    job_name = f'fairing-notebook-append-job-{uuid.uuid4().hex[:4]}'\n",
    "\n",
    "\n",
    "    fairing.config.set_builder('append', registry=CONTAINER_REGISTRY, image_name=\"fairing-notebook-append-job\",\n",
    "                               base_image=\"tensorflow/tensorflow:2.1.0-py3\")\n",
    "\n",
    "    fairing.config.set_deployer('job', namespace=namespace, job_name=job_name, cleanup=False, stream_log=True)\n",
    "\n",
    "    fairing.config.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200430 12:47:40 config:134] Using preprocessor: <kubeflow.fairing.preprocessors.converted_notebook.ConvertNotebookPreprocessor object at 0x7f87b81e1e80>\n",
      "[I 200430 12:47:40 config:136] Using builder: <kubeflow.fairing.builders.append.append.AppendBuilder object at 0x7f87a00e56d8>\n",
      "[I 200430 12:47:40 config:138] Using deployer: <kubeflow.fairing.deployers.job.job.Job object at 0x7f8792043198>\n",
      "[W 200430 12:47:40 append:50] Building image using Append builder...\n",
      "[I 200430 12:47:40 base:107] Creating docker context: /tmp/fairing_context_3pjrujas\n",
      "[I 200430 12:47:40 converted_notebook:127] Converting fairing_notebook_append_job.ipynb to fairing_notebook_append_job.py\n",
      "[I 200430 12:47:40 docker_creds_:234] Loading Docker credentials for repository 'tensorflow/tensorflow:2.1.0-py3'\n",
      "[W 200430 12:47:43 append:54] Image successfully built in 2.5867218380008126s.\n",
      "[W 200430 12:47:43 append:94] Pushing image kangwoo/fairing-notebook-append-job:F0768BF2...\n",
      "[I 200430 12:47:43 docker_creds_:234] Loading Docker credentials for repository 'kangwoo/fairing-notebook-append-job:F0768BF2'\n",
      "[W 200430 12:47:43 append:81] Uploading kangwoo/fairing-notebook-append-job:F0768BF2\n",
      "[I 200430 12:47:47 docker_session_:284] Layer sha256:4c1d20cdee96111c8acf1858b62655a37ce81ae48648993542b7ac363ac5c0e5 pushed.\n",
      "[I 200430 12:47:48 docker_session_:284] Layer sha256:053c8b8c686ab70140e12e17c10732b39b3f7d474f5330794bac1c95c510d469 pushed.\n",
      "[I 200430 12:47:48 docker_session_:284] Layer sha256:107f0b841886b4e032a6ced874db81b71dcdc5e6827b6c0d195defe4c6e661da pushed.\n",
      "[I 200430 12:47:49 docker_session_:284] Layer sha256:0d3160e1d0de4061b5b32ee09af687b898921d36ed9556df5910ddc3104449cd pushed.\n",
      "[I 200430 12:47:52 docker_session_:284] Layer sha256:edc69fe5c6be6938f490e5f91cdb6369799b4a509fd72c292e0cd6fdb3c345b3 pushed.\n",
      "[I 200430 12:47:52 docker_session_:284] Layer sha256:73c602a4c47800078fb8c79ba7bbcc65c43744f83dbc36250aacf20ce8d74a1e pushed.\n",
      "[I 200430 12:47:53 docker_session_:284] Layer sha256:75c61371a2e390c1d05234b28163580c90c2e26c6d245984a4da73f9f022c102 pushed.\n",
      "[I 200430 12:47:55 docker_session_:284] Layer sha256:c8e37668deea784f47c8726d934adc12b8d20a2b1c50b0b0c18cb62771cd3684 pushed.\n",
      "[I 200430 12:47:55 docker_session_:284] Layer sha256:8592f093fc78e0d933851ed625592627241c475dd46adad77f37dec9cc867446 pushed.\n",
      "[I 200430 12:48:16 docker_session_:284] Layer sha256:2746a4a261c9e18bfd7ff0429c18fd7522acc14fa4c7ec8ab37ba5ebaadbc584 pushed.\n",
      "[I 200430 12:48:23 docker_session_:284] Layer sha256:e52cad4ccd832fc331516c5a5632fdd08c37d711ff243c7e04d6e8c374b9c474 pushed.\n",
      "[I 200430 12:49:32 docker_session_:284] Layer sha256:e97116da5f9876a95d0d3f0fd1e3bcc48721f9ac6351ce23aaa3d261b4f9b0d6 pushed.\n",
      "[I 200430 12:56:12 docker_session_:284] Layer sha256:dccb0709d7fb37e513a933c3848be077f0e514e41a084bd9f3f27dcde169ae20 pushed.\n",
      "[I 200430 12:56:13 docker_session_:334] Finished upload of: kangwoo/fairing-notebook-append-job:F0768BF2\n",
      "[W 200430 12:56:13 append:99] Pushed image kangwoo/fairing-notebook-append-job:F0768BF2 in 509.77850424999633s.\n",
      "[W 200430 12:56:13 job:101] The job fairing-notebook-append-job-2108 launched.\n",
      "[W 200430 12:56:13 manager:296] Waiting for fairing-notebook-append-job-2108-9q2gz to start...\n",
      "[W 200430 12:56:13 manager:296] Waiting for fairing-notebook-append-job-2108-9q2gz to start...\n",
      "[W 200430 12:56:13 manager:296] Waiting for fairing-notebook-append-job-2108-9q2gz to start...\n",
      "[I 200430 12:56:20 manager:302] Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-30 12:56:20.511155: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-04-30 12:56:20.511219: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-04-30 12:56:20.511227: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "TensorFlow version:  2.1.0\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      " 8044544/11490434 [====================>.........] - ETA: 72\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "2020-04-30 12:56:22.145582: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-04-30 12:56:22.145598: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-04-30 12:56:22.145626: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2020-04-30 12:56:22.145730: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-04-30 12:56:22.169081: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600115000 Hz\n",
      "2020-04-30 12:56:22.169763: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4b86060 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-30 12:56:22.169798: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #\n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0\n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480\n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0\n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290\n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      " 7648/48000 [===>..........................] - ETA: 2s - loss: 0.6896 - accuracy: 0.8096\n",
      "16992/48000 [=========>....................] - ETA: 1s - loss: 0.4926 - accuracy: 0.85\n",
      "26048/48000 [===============>..............] - ETA: 0s - loss: 0.4334 - accuracy: 0.87\n",
      "35136/48000 [====================>.........] - ETA: 0s - loss: 0.3840 - accuracy: 0.88\n",
      "42880/48000 [=========================>....] - ETA: 0s - loss: 0.3493 - accuracy: 0.898\n",
      "48000/48000 [==============================] - 2s 43us/sample - loss: 0.3329 - accuracy: 0.9025 - val_loss: 0.1647 - val_accuracy: 0.9522\n",
      "Epoch 2/5\n",
      " 7328/48000 [===>..........................] - ETA: 1s - loss: 0.1857 - accuracy: 0.94\n",
      "16224/48000 [=========>....................] - ETA: 1s - loss: 0.1753 - accuracy: 0.94\n",
      "25600/48000 [===============>..............] - ETA: 0s - loss: 0.1725 - accuracy: 0.94\n",
      "34848/48000 [===================>..........] - ETA: 0s - loss: 0.1683 - accuracy: 0.94\n",
      "42592/48000 [=========================>....] - ETA: 0s - loss: 0.1644 - accuracy: 0.951\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.1618 - accuracy: 0.9519 - val_loss: 0.1211 - val_accuracy: 0.9626\n",
      "Epoch 3/5\n",
      " 7520/48000 [===>..........................] - ETA: 1s - loss: 0.1223 - accuracy: 0.96\n",
      "16704/48000 [=========>....................] - ETA: 1s - loss: 0.1232 - accuracy: 0.96\n",
      "25568/48000 [==============>...............] - ETA: 0s - loss: 0.1212 - accuracy: 0.96\n",
      "34912/48000 [===================>..........] - ETA: 0s - loss: 0.1206 - accuracy: 0.96\n",
      "42432/48000 [=========================>....] - ETA: 0s - loss: 0.1187 - accuracy: 0.964\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.1177 - accuracy: 0.9646 - val_loss: 0.1023 - val_accuracy: 0.9687\n",
      "Epoch 4/5\n",
      " 7744/48000 [===>..........................] - ETA: 1s - loss: 0.0981 - accuracy: 0.97\n",
      "16736/48000 [=========>....................] - ETA: 1s - loss: 0.0969 - accuracy: 0.96\n",
      "26176/48000 [===============>..............] - ETA: 0s - loss: 0.0951 - accuracy: 0.97\n",
      "35232/48000 [====================>.........] - ETA: 0s - loss: 0.0932 - accuracy: 0.97\n",
      "42496/48000 [=========================>....] - ETA: 0s - loss: 0.0947 - accuracy: 0.970\n",
      "48000/48000 [==============================] - 2s 39us/sample - loss: 0.0942 - accuracy: 0.9705 - val_loss: 0.0869 - val_accuracy: 0.9728\n",
      "Epoch 5/5\n",
      " 6976/48000 [===>..........................] - ETA: 1s - loss: 0.0853 - accuracy: 0.97\n",
      "16320/48000 [=========>....................] - ETA: 1s - loss: 0.0834 - accuracy: 0.97\n",
      "25120/48000 [==============>...............] - ETA: 0s - loss: 0.0834 - accuracy: 0.97\n",
      "34080/48000 [===================>..........] - ETA: 0s - loss: 0.0802 - accuracy: 0.97\n",
      "41568/48000 [========================>.....] - ETA: 0s - loss: 0.0813 - accuracy: 0.975\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.0810 - accuracy: 0.9757 - val_loss: 0.0834 - val_accuracy: 0.9748\n",
      "Test accuracy:  0.9758\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    if os.getenv('FAIRING_RUNTIME', None) is None:\n",
    "        fairing_run()\n",
    "    else:\n",
    "        train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
