{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def train():\n",
    "    import tensorflow as tf\n",
    "\n",
    "    print(\"TensorFlow version: \", tf.__version__)\n",
    "\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    print(\"Training...\")\n",
    "    model.fit(x_train, y_train, epochs=5, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model on test set\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairing_run():\n",
    "    import uuid\n",
    "    from kubeflow import fairing\n",
    "\n",
    "    CONTAINER_REGISTRY = 'kangwoo'\n",
    "\n",
    "    namespace = 'admin'\n",
    "    job_name = f'fairing-fullnotebook-append-job-{uuid.uuid4().hex[:4]}'\n",
    "\n",
    "    fairing.config.set_preprocessor('full_notebook')\n",
    "\n",
    "    fairing.config.set_builder('append', registry=CONTAINER_REGISTRY, \n",
    "                               image_name=\"fairing-fullnotebook-append-job\",\n",
    "                               base_image=\"kangwoo/tensorflow-papermill:0.0.1\")\n",
    "\n",
    "    fairing.config.set_deployer('job', namespace=namespace, job_name=job_name, cleanup=False, stream_log=True)\n",
    "\n",
    "    fairing.config.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 200430 13:54:52 config:134] Using preprocessor: <kubeflow.fairing.preprocessors.full_notebook.FullNotebookPreProcessor object at 0x7fdca831ceb8>\n",
      "[I 200430 13:54:52 config:136] Using builder: <kubeflow.fairing.builders.append.append.AppendBuilder object at 0x7fdc81b4afd0>\n",
      "[I 200430 13:54:52 config:138] Using deployer: <kubeflow.fairing.deployers.job.job.Job object at 0x7fdca80cd668>\n",
      "[W 200430 13:54:52 append:50] Building image using Append builder...\n",
      "[I 200430 13:54:52 base:107] Creating docker context: /tmp/fairing_context_yn3l9ukk\n",
      "[I 200430 13:54:52 docker_creds_:234] Loading Docker credentials for repository 'kangwoo/tensorflow-papermill:0.0.1'\n",
      "[W 200430 13:54:55 append:54] Image successfully built in 2.8594911090040114s.\n",
      "[W 200430 13:54:55 append:94] Pushing image kangwoo/fairing-fullnotebook-append-job:561D7A4D...\n",
      "[I 200430 13:54:55 docker_creds_:234] Loading Docker credentials for repository 'kangwoo/fairing-fullnotebook-append-job:561D7A4D'\n",
      "[W 200430 13:54:56 append:81] Uploading kangwoo/fairing-fullnotebook-append-job:561D7A4D\n",
      "[I 200430 13:54:59 docker_session_:284] Layer sha256:67e529d4d4317f2f051210d3dd298ad358b252b0a5083ad3b19860172d203a07 pushed.\n",
      "[I 200430 13:55:01 docker_session_:284] Layer sha256:4c1d20cdee96111c8acf1858b62655a37ce81ae48648993542b7ac363ac5c0e5 pushed.\n",
      "[I 200430 13:55:01 docker_session_:284] Layer sha256:c8e37668deea784f47c8726d934adc12b8d20a2b1c50b0b0c18cb62771cd3684 pushed.\n",
      "[I 200430 13:55:01 docker_session_:284] Layer sha256:107f0b841886b4e032a6ced874db81b71dcdc5e6827b6c0d195defe4c6e661da pushed.\n",
      "[I 200430 13:55:02 docker_session_:284] Layer sha256:8592f093fc78e0d933851ed625592627241c475dd46adad77f37dec9cc867446 pushed.\n",
      "[I 200430 13:55:05 docker_session_:284] Layer sha256:0d3160e1d0de4061b5b32ee09af687b898921d36ed9556df5910ddc3104449cd pushed.\n",
      "[I 200430 13:55:05 docker_session_:284] Layer sha256:edc69fe5c6be6938f490e5f91cdb6369799b4a509fd72c292e0cd6fdb3c345b3 pushed.\n",
      "[I 200430 13:55:05 docker_session_:284] Layer sha256:d3e86fe2423829f51bafbf045b2781a92ea1e07962bfdba5a0ddb39f470eedb0 pushed.\n",
      "[I 200430 13:55:06 docker_session_:284] Layer sha256:75c61371a2e390c1d05234b28163580c90c2e26c6d245984a4da73f9f022c102 pushed.\n",
      "[I 200430 13:55:21 docker_session_:284] Layer sha256:2746a4a261c9e18bfd7ff0429c18fd7522acc14fa4c7ec8ab37ba5ebaadbc584 pushed.\n",
      "[I 200430 13:55:37 docker_session_:284] Layer sha256:e52cad4ccd832fc331516c5a5632fdd08c37d711ff243c7e04d6e8c374b9c474 pushed.\n",
      "[I 200430 13:56:20 docker_session_:284] Layer sha256:2b6f330da38f8f9bfe99bfad03eb7768300c89eb3bf4b86ab89f567ce7426b4d pushed.\n",
      "[I 200430 13:56:49 docker_session_:284] Layer sha256:e97116da5f9876a95d0d3f0fd1e3bcc48721f9ac6351ce23aaa3d261b4f9b0d6 pushed.\n",
      "[I 200430 14:03:00 docker_session_:284] Layer sha256:dccb0709d7fb37e513a933c3848be077f0e514e41a084bd9f3f27dcde169ae20 pushed.\n",
      "[I 200430 14:03:01 docker_session_:334] Finished upload of: kangwoo/fairing-fullnotebook-append-job:561D7A4D\n",
      "[W 200430 14:03:01 append:99] Pushed image kangwoo/fairing-fullnotebook-append-job:561D7A4D in 485.3990217690007s.\n",
      "[W 200430 14:03:01 job:101] The job fairing-fullnotebook-append-job-77c4 launched.\n",
      "[W 200430 14:03:01 manager:296] Waiting for fairing-fullnotebook-append-job-77c4-7nb6r to start...\n",
      "[W 200430 14:03:01 manager:296] Waiting for fairing-fullnotebook-append-job-77c4-7nb6r to start...\n",
      "[W 200430 14:03:01 manager:296] Waiting for fairing-fullnotebook-append-job-77c4-7nb6r to start...\n",
      "[I 200430 14:03:21 manager:302] Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Notebook:  fairing_fullnotebook_append_job.ipynb\n",
      "Output Notebook: fairing_output_notebook.ipynb\n",
      "Executing notebook with kernel: python3\n",
      "Executing Cell 1---------------------------------------\n",
      "Ending Cell 1------------------------------------------\n",
      "Executing Cell 2---------------------------------------\n",
      "Ending Cell 2------------------------------------------\n",
      "Executing Cell 3---------------------------------------\n",
      "2020-04-30 14:03:22.865141: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-04-30 14:03:22.865196: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-04-30 14:03:22.865202: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "TensorFlow version:  2.1.0\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\n",
      "    8192/11490434 [..............................] - ETA: 2s\n",
      "   49152/11490434 [..............................] - ETA: 12s\n",
      "  147456/11490434 [..............................] - ETA: 8s\n",
      "  450560/11490434 [>.............................] - ETA: 3s\n",
      " 1343488/11490434 [==>...........................] - ETA: 1s\n",
      " 3850240/11490434 [=========>....................] - ETA: 0s\n",
      " 4030464/11490434 [=========>....................] - ETA: 0s\n",
      " 7897088/11490434 [===================>..........] - ETA: 0s\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "\n",
      "2020-04-30 14:03:24.477375: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-04-30 14:03:24.477392: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-04-30 14:03:24.477412: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2020-04-30 14:03:24.477516: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-04-30 14:03:24.481684: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600115000 Hz\n",
      "2020-04-30 14:03:24.482386: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x45792a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-30 14:03:24.482408: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #\n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0\n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480\n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0\n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290\n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training...\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "\n",
      "   32/48000 [..............................] - ETA: 3:55 - loss: 2.3062 - accuracy: 0.1250\n",
      " 1440/48000 [..............................] - ETA: 6s - loss: 1.3362 - accuracy: 0.6028\n",
      " 2912/48000 [>.............................] - ETA: 4s - loss: 0.9948 - accuracy: 0.7074\n",
      " 4352/48000 [=>............................] - ETA: 3s - loss: 0.8446 - accuracy: 0.7523\n",
      " 5856/48000 [==>...........................] - ETA: 2s - loss: 0.7386 - accuracy: 0.7830\n",
      " 7392/48000 [===>..........................] - ETA: 2s - loss: 0.6717 - accuracy: 0.8006\n",
      " 8896/48000 [====>.........................] - ETA: 2s - loss: 0.6246 - accuracy: 0.8149\n",
      "10336/48000 [=====>........................] - ETA: 1s - loss: 0.5929 - accuracy: 0.8251\n",
      "11648/48000 [======>.......................] - ETA: 1s - loss: 0.5668 - accuracy: 0.8327\n",
      "12960/48000 [=======>......................] - ETA: 1s - loss: 0.5472 - accuracy: 0.8389\n",
      "14432/48000 [========>.....................] - ETA: 1s - loss: 0.5227 - accuracy: 0.8462\n",
      "15936/48000 [========>.....................] - ETA: 1s - loss: 0.5056 - accuracy: 0.8518\n",
      "17472/48000 [=========>....................] - ETA: 1s - loss: 0.4886 - accuracy: 0.8574\n",
      "18976/48000 [==========>...................] - ETA: 1s - loss: 0.4699 - accuracy: 0.8630\n",
      "20576/48000 [===========>..................] - ETA: 1s - loss: 0.4570 - accuracy: 0.8673\n",
      "22112/48000 [============>.................] - ETA: 1s - loss: 0.4450 - accuracy: 0.8707\n",
      "23648/48000 [=============>................] - ETA: 0s - loss: 0.4319 - accuracy: 0.8750\n",
      "25024/48000 [==============>...............] - ETA: 0s - loss: 0.4243 - accuracy: 0.8768\n",
      "26624/48000 [===============>..............] - ETA: 0s - loss: 0.4122 - accuracy: 0.8801\n",
      "28064/48000 [================>.............] - ETA: 0s - loss: 0.4042 - accuracy: 0.8829\n",
      "29504/48000 [=================>............] - ETA: 0s - loss: 0.3965 - accuracy: 0.8852\n",
      "31008/48000 [==================>...........] - ETA: 0s - loss: 0.3902 - accuracy: 0.8869\n",
      "32448/48000 [===================>..........] - ETA: 0s - loss: 0.3839 - accuracy: 0.8886\n",
      "33920/48000 [====================>.........] - ETA: 0s - loss: 0.3793 - accuracy: 0.8898\n",
      "35424/48000 [=====================>........] - ETA: 0s - loss: 0.3739 - accuracy: 0.8915\n",
      "36928/48000 [======================>.......] - ETA: 0s - loss: 0.3685 - accuracy: 0.8931\n",
      "38240/48000 [======================>.......] - ETA: 0s - loss: 0.3639 - accuracy: 0.8946\n",
      "39552/48000 [=======================>......] - ETA: 0s - loss: 0.3591 - accuracy: 0.8960\n",
      "41024/48000 [========================>.....] - ETA: 0s - loss: 0.3540 - accuracy: 0.8973\n",
      "42464/48000 [=========================>....] - ETA: 0s - loss: 0.3490 - accuracy: 0.8990\n",
      "43872/48000 [==========================>...] - ETA: 0s - loss: 0.3440 - accuracy: 0.9004\n",
      "45312/48000 [===========================>..] - ETA: 0s - loss: 0.3398 - accuracy: 0.9015\n",
      "46784/48000 [============================>.] - ETA: 0s - loss: 0.3340 - accuracy: 0.9033\n",
      "48000/48000 [==============================] - 2s 44us/sample - loss: 0.3307 - accuracy: 0.9043 - val_loss: 0.1681 - val_accuracy: 0.9508\n",
      "\n",
      "Epoch 2/5\n",
      "   32/48000 [..............................] - ETA: 3s - loss: 0.2402 - accuracy: 0.9375\n",
      " 1472/48000 [..............................] - ETA: 1s - loss: 0.1726 - accuracy: 0.9524\n",
      " 2976/48000 [>.............................] - ETA: 1s - loss: 0.1767 - accuracy: 0.9459\n",
      " 4448/48000 [=>............................] - ETA: 1s - loss: 0.1809 - accuracy: 0.9442\n",
      " 5856/48000 [==>...........................] - ETA: 1s - loss: 0.1736 - accuracy: 0.9464\n",
      " 7392/48000 [===>..........................] - ETA: 1s - loss: 0.1742 - accuracy: 0.9447\n",
      " 8800/48000 [====>.........................] - ETA: 1s - loss: 0.1781 - accuracy: 0.9441\n",
      "10368/48000 [=====>........................] - ETA: 1s - loss: 0.1717 - accuracy: 0.9461\n",
      "12000/48000 [======>.......................] - ETA: 1s - loss: 0.1734 - accuracy: 0.9456\n",
      "13504/48000 [=======>......................] - ETA: 1s - loss: 0.1715 - accuracy: 0.9469\n",
      "14912/48000 [========>.....................] - ETA: 1s - loss: 0.1692 - accuracy: 0.9480\n",
      "16480/48000 [=========>....................] - ETA: 1s - loss: 0.1712 - accuracy: 0.9474\n",
      "17888/48000 [==========>...................] - ETA: 1s - loss: 0.1705 - accuracy: 0.9480\n",
      "19424/48000 [===========>..................] - ETA: 0s - loss: 0.1712 - accuracy: 0.9481\n",
      "20992/48000 [============>.................] - ETA: 0s - loss: 0.1709 - accuracy: 0.9481\n",
      "22528/48000 [=============>................] - ETA: 0s - loss: 0.1690 - accuracy: 0.9490\n",
      "23936/48000 [=============>................] - ETA: 0s - loss: 0.1687 - accuracy: 0.9493\n",
      "25472/48000 [==============>...............] - ETA: 0s - loss: 0.1686 - accuracy: 0.9493\n",
      "26848/48000 [===============>..............] - ETA: 0s - loss: 0.1680 - accuracy: 0.9496\n",
      "28224/48000 [================>.............] - ETA: 0s - loss: 0.1670 - accuracy: 0.9498\n",
      "29728/48000 [=================>............] - ETA: 0s - loss: 0.1669 - accuracy: 0.9497\n",
      "31200/48000 [==================>...........] - ETA: 0s - loss: 0.1661 - accuracy: 0.9499\n",
      "32608/48000 [===================>..........] - ETA: 0s - loss: 0.1658 - accuracy: 0.9500\n",
      "34112/48000 [====================>.........] - ETA: 0s - loss: 0.1657 - accuracy: 0.9500\n",
      "35488/48000 [=====================>........] - ETA: 0s - loss: 0.1653 - accuracy: 0.9500\n",
      "37024/48000 [======================>.......] - ETA: 0s - loss: 0.1656 - accuracy: 0.9499\n",
      "38496/48000 [=======================>......] - ETA: 0s - loss: 0.1659 - accuracy: 0.9498\n",
      "39808/48000 [=======================>......] - ETA: 0s - loss: 0.1659 - accuracy: 0.9499\n",
      "41344/48000 [========================>.....] - ETA: 0s - loss: 0.1649 - accuracy: 0.9501\n",
      "42784/48000 [=========================>....] - ETA: 0s - loss: 0.1643 - accuracy: 0.9506\n",
      "44320/48000 [==========================>...] - ETA: 0s - loss: 0.1632 - accuracy: 0.9510\n",
      "45792/48000 [===========================>..] - ETA: 0s - loss: 0.1626 - accuracy: 0.9512\n",
      "47360/48000 [============================>.] - ETA: 0s - loss: 0.1616 - accuracy: 0.9515\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.1617 - accuracy: 0.9514 - val_loss: 0.1194 - val_accuracy: 0.9666\n",
      "\n",
      "Epoch 3/5\n",
      "   32/48000 [..............................] - ETA: 4s - loss: 0.0772 - accuracy: 0.9688\n",
      " 1536/48000 [..............................] - ETA: 1s - loss: 0.1153 - accuracy: 0.9648\n",
      " 3040/48000 [>.............................] - ETA: 1s - loss: 0.1222 - accuracy: 0.9641\n",
      " 4640/48000 [=>............................] - ETA: 1s - loss: 0.1231 - accuracy: 0.9623\n",
      " 6080/48000 [==>...........................] - ETA: 1s - loss: 0.1231 - accuracy: 0.9625\n",
      " 7456/48000 [===>..........................] - ETA: 1s - loss: 0.1277 - accuracy: 0.9616\n",
      " 8640/48000 [====>.........................] - ETA: 1s - loss: 0.1281 - accuracy: 0.9611\n",
      "10144/48000 [=====>........................] - ETA: 1s - loss: 0.1269 - accuracy: 0.9616\n",
      "11680/48000 [======>.......................] - ETA: 1s - loss: 0.1307 - accuracy: 0.9608\n",
      "13088/48000 [=======>......................] - ETA: 1s - loss: 0.1292 - accuracy: 0.9613\n",
      "14624/48000 [========>.....................] - ETA: 1s - loss: 0.1295 - accuracy: 0.9617\n",
      "16096/48000 [=========>....................] - ETA: 1s - loss: 0.1283 - accuracy: 0.9623\n",
      "17632/48000 [==========>...................] - ETA: 1s - loss: 0.1272 - accuracy: 0.9627\n",
      "19136/48000 [==========>...................] - ETA: 0s - loss: 0.1273 - accuracy: 0.9625\n",
      "20640/48000 [===========>..................] - ETA: 0s - loss: 0.1242 - accuracy: 0.9631\n",
      "22080/48000 [============>.................] - ETA: 0s - loss: 0.1235 - accuracy: 0.9631\n",
      "23520/48000 [=============>................] - ETA: 0s - loss: 0.1232 - accuracy: 0.9633\n",
      "24992/48000 [==============>...............] - ETA: 0s - loss: 0.1233 - accuracy: 0.9631\n",
      "26560/48000 [===============>..............] - ETA: 0s - loss: 0.1216 - accuracy: 0.9637\n",
      "27968/48000 [================>.............] - ETA: 0s - loss: 0.1217 - accuracy: 0.9636\n",
      "29472/48000 [=================>............] - ETA: 0s - loss: 0.1216 - accuracy: 0.9642\n",
      "30848/48000 [==================>...........] - ETA: 0s - loss: 0.1225 - accuracy: 0.9640\n",
      "32384/48000 [===================>..........] - ETA: 0s - loss: 0.1242 - accuracy: 0.9635\n",
      "33984/48000 [====================>.........] - ETA: 0s - loss: 0.1241 - accuracy: 0.9636\n",
      "35456/48000 [=====================>........] - ETA: 0s - loss: 0.1246 - accuracy: 0.9635\n",
      "37088/48000 [======================>.......] - ETA: 0s - loss: 0.1232 - accuracy: 0.9639\n",
      "38688/48000 [=======================>......] - ETA: 0s - loss: 0.1231 - accuracy: 0.9638\n",
      "40128/48000 [========================>.....] - ETA: 0s - loss: 0.1225 - accuracy: 0.9638\n",
      "41568/48000 [========================>.....] - ETA: 0s - loss: 0.1219 - accuracy: 0.9637\n",
      "42976/48000 [=========================>....] - ETA: 0s - loss: 0.1217 - accuracy: 0.9638\n",
      "44480/48000 [==========================>...] - ETA: 0s - loss: 0.1210 - accuracy: 0.9639\n",
      "45952/48000 [===========================>..] - ETA: 0s - loss: 0.1212 - accuracy: 0.9639\n",
      "47488/48000 [============================>.] - ETA: 0s - loss: 0.1208 - accuracy: 0.9640\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.1212 - accuracy: 0.9640 - val_loss: 0.1048 - val_accuracy: 0.9701\n",
      "\n",
      "Epoch 4/5\n",
      "   32/48000 [..............................] - ETA: 3s - loss: 0.0542 - accuracy: 1.0000\n",
      " 1376/48000 [..............................] - ETA: 1s - loss: 0.0927 - accuracy: 0.9680\n",
      " 2944/48000 [>.............................] - ETA: 1s - loss: 0.0891 - accuracy: 0.9701\n",
      " 4448/48000 [=>............................] - ETA: 1s - loss: 0.0993 - accuracy: 0.9670\n",
      " 5920/48000 [==>...........................] - ETA: 1s - loss: 0.0956 - accuracy: 0.9686\n",
      " 7328/48000 [===>..........................] - ETA: 1s - loss: 0.0963 - accuracy: 0.9694\n",
      " 8864/48000 [====>.........................] - ETA: 1s - loss: 0.0964 - accuracy: 0.9701\n",
      "10368/48000 [=====>........................] - ETA: 1s - loss: 0.0959 - accuracy: 0.9709\n",
      "11904/48000 [======>.......................] - ETA: 1s - loss: 0.0959 - accuracy: 0.9704\n",
      "13376/48000 [=======>......................] - ETA: 1s - loss: 0.0967 - accuracy: 0.9694\n",
      "14912/48000 [========>.....................] - ETA: 1s - loss: 0.0974 - accuracy: 0.9694\n",
      "16320/48000 [=========>....................] - ETA: 1s - loss: 0.0981 - accuracy: 0.9695\n",
      "17728/48000 [==========>...................] - ETA: 1s - loss: 0.0984 - accuracy: 0.9693\n",
      "19200/48000 [===========>..................] - ETA: 0s - loss: 0.0990 - accuracy: 0.9692\n",
      "20544/48000 [===========>..................] - ETA: 0s - loss: 0.0998 - accuracy: 0.9692\n",
      "22144/48000 [============>.................] - ETA: 0s - loss: 0.0995 - accuracy: 0.9691\n",
      "23584/48000 [=============>................] - ETA: 0s - loss: 0.1000 - accuracy: 0.9690\n",
      "24992/48000 [==============>...............] - ETA: 0s - loss: 0.0996 - accuracy: 0.9691\n",
      "26528/48000 [===============>..............] - ETA: 0s - loss: 0.0982 - accuracy: 0.9695\n",
      "27904/48000 [================>.............] - ETA: 0s - loss: 0.0994 - accuracy: 0.9694\n",
      "29408/48000 [=================>............] - ETA: 0s - loss: 0.0993 - accuracy: 0.9694\n",
      "30976/48000 [==================>...........] - ETA: 0s - loss: 0.0994 - accuracy: 0.9695\n",
      "32448/48000 [===================>..........] - ETA: 0s - loss: 0.0988 - accuracy: 0.9699\n",
      "34016/48000 [====================>.........] - ETA: 0s - loss: 0.0985 - accuracy: 0.9700\n",
      "35616/48000 [=====================>........] - ETA: 0s - loss: 0.0984 - accuracy: 0.9700\n",
      "37088/48000 [======================>.......] - ETA: 0s - loss: 0.0985 - accuracy: 0.9700\n",
      "38688/48000 [=======================>......] - ETA: 0s - loss: 0.0986 - accuracy: 0.9700\n",
      "40160/48000 [========================>.....] - ETA: 0s - loss: 0.0976 - accuracy: 0.9703\n",
      "41568/48000 [========================>.....] - ETA: 0s - loss: 0.0979 - accuracy: 0.9704\n",
      "43008/48000 [=========================>....] - ETA: 0s - loss: 0.0983 - accuracy: 0.9703\n",
      "44384/48000 [==========================>...] - ETA: 0s - loss: 0.0982 - accuracy: 0.9703\n",
      "45728/48000 [===========================>..] - ETA: 0s - loss: 0.0986 - accuracy: 0.9703\n",
      "47232/48000 [============================>.] - ETA: 0s - loss: 0.0987 - accuracy: 0.9702\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.0989 - accuracy: 0.9701 - val_loss: 0.0978 - val_accuracy: 0.9714\n",
      "\n",
      "Epoch 5/5\n",
      "   32/48000 [..............................] - ETA: 2s - loss: 0.0680 - accuracy: 0.9688\n",
      " 1472/48000 [..............................] - ETA: 1s - loss: 0.0893 - accuracy: 0.9674\n",
      " 2912/48000 [>.............................] - ETA: 1s - loss: 0.0824 - accuracy: 0.9722\n",
      " 4416/48000 [=>............................] - ETA: 1s - loss: 0.0874 - accuracy: 0.9715\n",
      " 5952/48000 [==>...........................] - ETA: 1s - loss: 0.0864 - accuracy: 0.9721\n",
      " 7296/48000 [===>..........................] - ETA: 1s - loss: 0.0831 - accuracy: 0.9738\n",
      " 8800/48000 [====>.........................] - ETA: 1s - loss: 0.0823 - accuracy: 0.9740\n",
      "10400/48000 [=====>........................] - ETA: 1s - loss: 0.0823 - accuracy: 0.9740\n",
      "11840/48000 [======>.......................] - ETA: 1s - loss: 0.0810 - accuracy: 0.9746\n",
      "13248/48000 [=======>......................] - ETA: 1s - loss: 0.0808 - accuracy: 0.9750\n",
      "14816/48000 [========>.....................] - ETA: 1s - loss: 0.0806 - accuracy: 0.9754\n",
      "16352/48000 [=========>....................] - ETA: 1s - loss: 0.0815 - accuracy: 0.9755\n",
      "17856/48000 [==========>...................] - ETA: 1s - loss: 0.0824 - accuracy: 0.9749\n",
      "19264/48000 [===========>..................] - ETA: 0s - loss: 0.0837 - accuracy: 0.9743\n",
      "20832/48000 [============>.................] - ETA: 0s - loss: 0.0846 - accuracy: 0.9741\n",
      "22368/48000 [============>.................] - ETA: 0s - loss: 0.0849 - accuracy: 0.9738\n",
      "23840/48000 [=============>................] - ETA: 0s - loss: 0.0842 - accuracy: 0.9739\n",
      "25248/48000 [==============>...............] - ETA: 0s - loss: 0.0843 - accuracy: 0.9740\n",
      "26784/48000 [===============>..............] - ETA: 0s - loss: 0.0843 - accuracy: 0.9741\n",
      "28384/48000 [================>.............] - ETA: 0s - loss: 0.0844 - accuracy: 0.9738\n",
      "29984/48000 [=================>............] - ETA: 0s - loss: 0.0847 - accuracy: 0.9741\n",
      "31456/48000 [==================>...........] - ETA: 0s - loss: 0.0849 - accuracy: 0.9740\n",
      "32960/48000 [===================>..........] - ETA: 0s - loss: 0.0835 - accuracy: 0.9745\n",
      "34432/48000 [====================>.........] - ETA: 0s - loss: 0.0833 - accuracy: 0.9745\n",
      "35776/48000 [=====================>........] - ETA: 0s - loss: 0.0837 - accuracy: 0.9744\n",
      "37280/48000 [======================>.......] - ETA: 0s - loss: 0.0833 - accuracy: 0.9746\n",
      "38624/48000 [=======================>......] - ETA: 0s - loss: 0.0837 - accuracy: 0.9744\n",
      "40128/48000 [========================>.....] - ETA: 0s - loss: 0.0839 - accuracy: 0.9742\n",
      "41600/48000 [=========================>....] - ETA: 0s - loss: 0.0837 - accuracy: 0.9741\n",
      "43104/48000 [=========================>....] - ETA: 0s - loss: 0.0840 - accuracy: 0.9739\n",
      "44608/48000 [==========================>...] - ETA: 0s - loss: 0.0841 - accuracy: 0.9737\n",
      "45984/48000 [===========================>..] - ETA: 0s - loss: 0.0845 - accuracy: 0.9736\n",
      "47552/48000 [============================>.] - ETA: 0s - loss: 0.0851 - accuracy: 0.9736\n",
      "48000/48000 [==============================] - 2s 40us/sample - loss: 0.0852 - accuracy: 0.9736 - val_loss: 0.0867 - val_accuracy: 0.9736\n",
      "\n",
      "Test accuracy:  0.9757\n",
      "\n",
      "Ending Cell 3------------------------------------------\n",
      "Executing Cell 4---------------------------------------\n",
      "Ending Cell 4------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    if os.getenv('FAIRING_RUNTIME', None) is None:\n",
    "        fairing_run()\n",
    "    else:\n",
    "        train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
